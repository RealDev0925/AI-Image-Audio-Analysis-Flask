{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "import actions\n",
    "import funcs_database\n",
    "import funcs_supabase\n",
    "import requests\n",
    "\n",
    "\n",
    "settings = {}\n",
    "project_id = 27\n",
    "final_video_name = 'project-27'\n",
    "\n",
    "\n",
    "words_list = funcs_supabase.select_data(\"video_creator_projects\", \"id\", project_id)[0][\"words_list\"]\n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(final_video_name):\n",
    "    base_path = \"composed_videos\"\n",
    "    new_folder_path = os.path.join(base_path, final_video_name)\n",
    "\n",
    "    # Create the new folder if it doesn't exist\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "        print(f\"'{new_folder_path}' has been created!\")\n",
    "    else:\n",
    "        print(f\"'{new_folder_path}' already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_file_from_url(url, save_path):\n",
    "    \"\"\"\n",
    "    Download a file from the provided URL and save it to the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL of the file to download.\n",
    "    - save_path (str): The local path where the file should be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the directory structure exists\n",
    "    directory = os.path.dirname(save_path)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(save_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "\n",
    "    print(f\"File downloaded and saved to {save_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# download_file_from_url(\"https://example.com/file.zip\", \"local_folder/file.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "# Download speech and subs\n",
    "project_data = funcs_supabase.select_data(table='video_creator_projects', column='id', value=project_id)\n",
    "print(project_data)\n",
    "\n",
    "filepath = f\"composed_videos/{final_video_name}/subs.srt\"\n",
    "subs = project_data[0]['subtitles_file']\n",
    "download_file_from_url(subs, filepath)\n",
    "\n",
    "filepath = f\"composed_videos/{final_video_name}/speech.mp3\"\n",
    "speech = project_data[0]['speech_audio']\n",
    "download_file_from_url(speech, filepath)\n",
    "speech_clip = AudioFileClip(filepath)\n",
    "\n",
    "\n",
    "\n",
    "last_word_end_time = words_list[-1]['end']\n",
    "first_word_time = words_list[0]['start']\n",
    "print(f\"first word start time {first_word_time}\")\n",
    "print(f\"last word end time {last_word_end_time}\")\n",
    "\n",
    "speech_audio = \"composed_videos/project17-2/speech.mp3\"\n",
    "audio = AudioFileClip(speech_audio)\n",
    "audio_duration = audio.duration # this will print the duration of the audio in seconds\n",
    "print(f\"audio duration {audio_duration}\")\n",
    "audio.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "def get_file_extension(url):\n",
    "    # Unquote the URL to handle any encoded characters\n",
    "    url = unquote(url)\n",
    "    # Parse the URL into its components\n",
    "    parsed_url = urlparse(url)\n",
    "    # Get the path component of the URL and then extract the file extension\n",
    "    return os.path.splitext(parsed_url.path)[1][1:]\n",
    "\n",
    "def download_media_for_list(scenes_data_list):\n",
    "    downloaded_files_list = []\n",
    "    for sc in scenes_data_list:\n",
    "        # print(i)\n",
    "        # print(sc)\n",
    "        media_url = sc.get('media_url', None)\n",
    "        media_type = sc.get('media_type', None)\n",
    "        media_url_remote = sc.get('media_url_remote', None)\n",
    "        scene_id = sc.get('id', None)\n",
    "\n",
    "\n",
    "        # sometimes if url is missing but remote url is present\n",
    "        if media_url is None and media_url_remote is not None:\n",
    "            media_url = media_url_remote\n",
    "\n",
    "        url_extension = get_file_extension(media_url)\n",
    "        if url_extension == '':\n",
    "            if media_type == 'image':\n",
    "                url_extension = 'png'\n",
    "            elif media_type == 'video':\n",
    "                url_extension = 'mp4'\n",
    "            else:\n",
    "                url_extension = 'png'\n",
    "\n",
    "\n",
    "                \n",
    "        print(url_extension)\n",
    "\n",
    "        filename = f\"composed_videos/{final_video_name}/{scene_id}.{url_extension}\"\n",
    "        print(filename)\n",
    "\n",
    "        download_file_from_url(media_url, filename)\n",
    "\n",
    "        downloaded_files_list.append(filename)\n",
    "\n",
    "    return downloaded_files_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(media_url)\n",
    "    # print(media_type)\n",
    "    # print(media_url_remote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def zip_folder(folder_path, output_filename):\n",
    "    \"\"\"\n",
    "    Zips the contents of a folder into a .zip file.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: Path to the folder you want to zip.\n",
    "    - output_filename: Name of the output .zip file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a ZipFile Object\n",
    "    with zipfile.ZipFile(output_filename, 'w') as zipf:\n",
    "        # Walk through the folder and add all files to the ZipFile\n",
    "        for foldername, subfolders, filenames in os.walk(folder_path):\n",
    "            for filename in filenames:\n",
    "                # Create complete filepath of file in directory\n",
    "                file_path = os.path.join(foldername, filename)\n",
    "                # Add file to zip\n",
    "                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
    "\n",
    "\n",
    "\n",
    "# folder = f\"composed_videos/{final_video_name}\"\n",
    "# zip_folder(folder, final_video_name + '.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def trim_clip(clip, start_trim, end_trim):\n",
    "    \"\"\"\n",
    "    Trim a video clip to fit a new length between start_trim and end_trim.\n",
    "    \n",
    "    :param clip: VideoFileClip instance representing the video to trim.\n",
    "    :param start_trim: Start trim point in seconds.\n",
    "    :param end_trim: End trim point in seconds.\n",
    "    \n",
    "    :return: Adjusted video clip.\n",
    "    \"\"\"\n",
    "    \n",
    "    current_duration = clip.duration\n",
    "    target_duration = end_trim - start_trim\n",
    "\n",
    "    print(f\"Current clip length: {current_duration}\")\n",
    "    print(f\"Target length: {target_duration}\")\n",
    "\n",
    "    if current_duration == target_duration:\n",
    "        print(\"Clip is already the target duration.\")\n",
    "        return clip\n",
    "    elif current_duration > target_duration:\n",
    "        print(\"Clip is longer than target duration. Trimming...\")\n",
    "        return clip.subclip(start_trim, end_trim)\n",
    "    else:\n",
    "        print(\"Clip is shorter than target duration. Slowing down to fit...\")\n",
    "        speed_factor = current_duration / target_duration\n",
    "        return clip.speedx(speed_factor)\n",
    "\n",
    "# Example usage\n",
    "# clip = VideoFileClip(\"composed_videos/final_video123/0.mp4\")\n",
    "# new_clip = trim_clip(clip, start_trim=4, end_trim=8)\n",
    "# new_clip.write_videofile(\"output_video.mp4\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.fx.all import crop\n",
    "\n",
    "def crop_clip(video_clip, width=1600, height=900):\n",
    "    \"\"\"\n",
    "    Crop a video to a specific size, maintaining its center.\n",
    "    \n",
    "    :param video_clip: VideoFileClip instance of the video.\n",
    "    :param width: Desired width of the cropped video.\n",
    "    :param height: Desired height of the cropped video.\n",
    "    \n",
    "    :return: Cropped (and possibly resized) VideoFileClip.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If clip's width and height match the desired dimensions, return the clip\n",
    "    if video_clip.w == width and video_clip.h == height:\n",
    "        print(\"Video is already the desired size\")\n",
    "        return video_clip\n",
    "    \n",
    "    current_aspect_ratio = video_clip.w / video_clip.h\n",
    "    target_aspect_ratio = width / height\n",
    "\n",
    "    # Calculate the cropping dimensions based on the aspect ratios\n",
    "    if current_aspect_ratio > target_aspect_ratio:\n",
    "        crop_width = video_clip.h * target_aspect_ratio\n",
    "        crop_height = video_clip.h\n",
    "    else:\n",
    "        crop_width = video_clip.w\n",
    "        crop_height = video_clip.w / target_aspect_ratio\n",
    "\n",
    "    # Crop the video clip\n",
    "    cropped_clip = crop(video_clip, width=crop_width, height=crop_height, \n",
    "                        x_center=video_clip.w/2, y_center=video_clip.h/2)\n",
    "\n",
    "    # Resize the cropped video to the desired dimensions\n",
    "    resized_clip = cropped_clip.resize(width=width, height=height)\n",
    "\n",
    "    return resized_clip\n",
    "\n",
    "\n",
    "# Usage\n",
    "# clip = VideoFileClip(\"composed_videos/final_video123/0.mp4\")\n",
    "# new_clip = crop_clip(clip, width=1600, height=900)\n",
    "# new_clip.write_videofile(\"output_video_2.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scenes_data_list(project_id):\n",
    "    scenes_list = actions.get_active_scenes(project_id)\n",
    "    \n",
    "    scenes_data_list = []\n",
    "    for scene in scenes_list:\n",
    "        scene_id = scene['id']\n",
    "        scene_data = funcs_database.get_scene_and_clip_by_id(scene_id)\n",
    "        # print(scene_data)\n",
    "        scenes_data_list.append(scene_data)\n",
    "\n",
    "    return scenes_data_list\n",
    "\n",
    "\n",
    "scenes_data_list = get_scenes_data_list(project_id)\n",
    "downloaded_files_list = download_media_for_list(scenes_data_list)\n",
    "\n",
    "if len(downloaded_files_list) == len(scenes_data_list):\n",
    "    print('All files downloaded successfully')\n",
    "\n",
    "# print(downloaded_files_list)\n",
    "# print(scenes_data_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene in scenes_data_list:\n",
    "    print(scene[\"id\"])\n",
    "    print(scene[\"timings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length_scenes = 0\n",
    "for item in scenes_data_list:\n",
    "    print(item[\"timings\"])\n",
    "    # total_length_scenes += item[\"timings\"[\"length\"]]\n",
    "    total_length_scenes = total_length_scenes + item[\"timings\"][\"length\"]\n",
    "print(total_length_scenes)\n",
    "\n",
    "\n",
    "\n",
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "def get_duration_of_mp3(file_path):\n",
    "    with AudioFileClip(file_path) as audio:\n",
    "        return audio.duration\n",
    "\n",
    "filepath = f\"composed_videos/{final_video_name}/speech.mp3\"\n",
    "\n",
    "duration_in_seconds = get_duration_of_mp3(filepath)\n",
    "print(f\"Duration of the MP3 file: {duration_in_seconds:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, ImageClip  \n",
    "import moviepy.editor as mpy\n",
    "from moviepy.video.fx.all import crop\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "initial_clip_list = []\n",
    "for file in downloaded_files_list:\n",
    "    print(file)\n",
    "\n",
    "    scene_id = file.split('/')[-1].split('.')[0]\n",
    "    print(scene_id)\n",
    "\n",
    "    scene_data = funcs_database.get_scene_and_clip_by_id(scene_id)\n",
    "    print(scene_data)\n",
    "\n",
    "    timings = scene_data['timings']\n",
    "    length = timings['length']\n",
    "\n",
    "\n",
    "    if file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "        clip = VideoFileClip(file)\n",
    "        initial_clip_list.append(clip)\n",
    "\n",
    "\n",
    "    elif file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        # Set the duration for how long you want each image to display\n",
    "        clip = ImageClip(file, duration=length)\n",
    "        initial_clip_list.append(clip)\n",
    "\n",
    "    else:\n",
    "        print(f\"Unsupported format: {file}\")\n",
    "\n",
    "\n",
    "\n",
    "    # clip = VideoFileClip(file)\n",
    "    # initial_clip_list.append(clip)\n",
    "\n",
    "print(initial_clip_list)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proceessed_clip_list = []\n",
    "\n",
    "for i, clip in enumerate(initial_clip_list):\n",
    "\n",
    "    scene_data = scenes_data_list[i]\n",
    "    timings = scene_data['timings']\n",
    "    length = timings['length']\n",
    "\n",
    "    # print(f\"scene length: {length}\")\n",
    "    \n",
    "    trimmed_clip = trim_clip(clip, start_trim=0, end_trim=length)\n",
    "    resized_clip = crop_clip(trimmed_clip, width=900, height=900)\n",
    "\n",
    "    proceessed_clip_list.append(resized_clip)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in proceessed_clip_list:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import concatenate_audioclips, AudioClip\n",
    "import numpy as np\n",
    "\n",
    "def combine_video_audio(video_clip, audio_clip, audio_silence):\n",
    "    # silence_array = np.zeros((int(audio_silence * audio_clip.fps),)).astype(\"float32\")\n",
    "    silence_array = np.zeros((int(audio_silence * audio_clip.fps * audio_clip.nchannels),)).astype(\"float32\")\n",
    "\n",
    "\n",
    "\n",
    "    silence = AudioClip(lambda t: silence_array, duration=audio_silence).set_fps(audio_clip.fps)\n",
    "\n",
    "\n",
    "\n",
    "    print(silence.fps, silence.nchannels, silence.duration)\n",
    "    print(speech_clip.fps, speech_clip.nchannels, speech_clip.duration)\n",
    "\n",
    "\n",
    "    combined_audio = concatenate_audioclips([silence, audio_clip])\n",
    "\n",
    "    combined_audio.write_audiofile(\"test_combined_audio.mp3\")\n",
    "\n",
    "\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "import numpy as np\n",
    "\n",
    "def add_gap_to_audio(audio_clip, beginning_gap, output_path):\n",
    "    # Load audio\n",
    "    # audio_clip = AudioFileClip(audio_path)\n",
    "    \n",
    "    # Create a silent audio clip of the given duration (gap)\n",
    "    silent_clip = AudioClip(lambda t: [0, 0], duration=beginning_gap).set_fps(audio_clip.fps)\n",
    "    \n",
    "    # Concatenate silent clip with the original audio\n",
    "    new_audio = concatenate_audioclips([silent_clip, audio_clip])\n",
    "    \n",
    "    # Write the audio with gap to the output file\n",
    "    new_audio.write_audiofile(output_path)\n",
    "\n",
    "# Example of using the function\n",
    "# add_gap_to_audio(\"input_audio.mp3\", 5, \"output_with_gap.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "def join_audio_video(audio, video, output_path):\n",
    "    \"\"\"\n",
    "    Join given audio and video files and save to output_path.\n",
    "\n",
    "    :param audio_path: path to the audio file\n",
    "    :param video_path: path to the video file\n",
    "    :param output_path: path to save the output video file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load audio and video clips\n",
    "    # audio = AudioFileClip(audio_path)\n",
    "    # video = VideoFileClip(video_path)\n",
    "    \n",
    "    # Set audio to video\n",
    "    video_with_audio = video.set_audio(audio)\n",
    "    \n",
    "    # Write the result to file\n",
    "    video_with_audio.write_videofile(output_path, audio_codec='aac')\n",
    "\n",
    "    return output_path\n",
    "\n",
    "# Example usage:\n",
    "# join_audio_video(\"path_to_audio.mp3\", \"path_to_video.mp4\", \"output_video.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clip = concatenate_videoclips(proceessed_clip_list)\n",
    "final_clip = final_clip.without_audio()\n",
    "print(final_clip.duration)\n",
    "\n",
    "\n",
    "speech_filepath = f\"composed_videos/{final_video_name}/speech.mp3\"\n",
    "speech_clip = AudioFileClip(speech_filepath)\n",
    "print(speech_clip.duration)\n",
    "\n",
    "# silence_gap = final_clip.duration - speech_clip.duration\n",
    "# silence_gap = round(silence_gap, 3)\n",
    "\n",
    "# new_audio_file = \"output_with_gap.mp3\"\n",
    "# add_gap_to_audio(speech_clip, silence_gap, new_audio_file)\n",
    "# output_audio_clip = AudioFileClip(new_audio_file)\n",
    "# print(output_audio_clip.duration)\n",
    "\n",
    "\n",
    "join_audio_video(speech_clip, final_clip, \"output_video1.mp4\")\n",
    "\n",
    "\n",
    "\n",
    "# final_clip = combine_video_audio(final_clip, audio_clip=speech_clip, audio_silence=silence_gap)\n",
    "\n",
    "# # final_clip.write_videofile(\"yolo7.mp4\")\n",
    "# final_clip.write_videofile(\"output.mp4\", codec=\"libx264\", audio_codec=\"aac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
