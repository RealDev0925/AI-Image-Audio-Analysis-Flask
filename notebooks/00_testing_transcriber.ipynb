{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transcriber\n",
    "import json\n",
    "audio_filepath = \"/Users/georgebennett/Documents/GitHub/script_writer/uploads/testsquare.mp3\"\n",
    "audio_file_binary = open(audio_filepath, \"rb\")\n",
    "word_segments = transcriber.get_word_segments(audio_file_binary)\n",
    "print(word_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of actual words with their timestamps: \n",
    "\n",
    "word_list = transcriber.process_word_segments(word_segments)\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_time_stamps(word_list):\n",
    "    \"\"\"\n",
    "    sometimes you get this situation:\n",
    "    {'word': 'money.', 'start': 11.88, 'end': 13.082, 'score': 0.752}\n",
    "    {'word': '72%'}\n",
    "    {'word': 'of', 'start': 13.622, 'end': 13.682, 'score': 0.753}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        fixed_list = []\n",
    "        for i, word_dict in enumerate(word_list):\n",
    "            new_dict = word_dict.copy()\n",
    "            \n",
    "            # If 'start' is missing in the current word dict\n",
    "            if 'start' not in new_dict:\n",
    "                # If it's the first element, set start to 0\n",
    "                if i == 0:\n",
    "                    new_dict['start'] = 0\n",
    "                # Otherwise, set start to end of previous word\n",
    "                else:\n",
    "                    new_dict['start'] = fixed_list[-1].get('end', 0)\n",
    "            \n",
    "            # If 'end' is missing in the current word dict\n",
    "            if 'end' not in new_dict:\n",
    "                # If it's the last element, set end to start + 0.5 (or any other default duration)\n",
    "                if i == len(word_list) - 1:\n",
    "                    new_dict['end'] = new_dict['start'] + 0.5\n",
    "                # Otherwise, set end to start of next word\n",
    "                else:\n",
    "                    new_dict['end'] = word_list[i + 1].get('start', new_dict['start'] + 0.5)\n",
    "\n",
    "            fixed_list.append(new_dict)\n",
    "\n",
    "        return fixed_list\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subtitle_blocks(words, char_limit):\n",
    "    \"\"\"\n",
    "    makes blocks like this \n",
    "    {'text': 'How to turn your phone into a gold', 'start': None, 'end': 1.61}\n",
    "    {'text': 'mine,', 'start': 1.63, 'end': 1.85}\n",
    "    {'text': 'the best kept secret in the world until', 'start': None, 'end': 4.032}\n",
    "    {'text': 'now.', 'start': 4.112, 'end': 4.333}\n",
    "    {'text': 'Nope,', 'start': None, 'end': 5.694}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Initialize variables\n",
    "    blocks = []\n",
    "    current_block = {\"text\": \"\", \"start\": None, \"end\": None}\n",
    "\n",
    "    for word_info in words:\n",
    "        word = word_info['word']\n",
    "        start_time = word_info['start']\n",
    "        end_time = word_info['end']\n",
    "\n",
    "        # Check if the word ends with punctuation\n",
    "        ends_in_punctuation = word[-1] in [\".\", \",\", \"!\", \"?\", \";\"]\n",
    "\n",
    "        # New block length if this word is added\n",
    "        new_block_length = len(current_block[\"text\"]) + len(word) + (1 if current_block[\"text\"] else 0)\n",
    "\n",
    "        # Initialize start time if starting a new block\n",
    "        if current_block[\"start\"] is None:\n",
    "            current_block[\"start\"] = start_time\n",
    "\n",
    "        # Append this word to the current block first, before checking for block completion\n",
    "        if current_block[\"text\"]:\n",
    "            current_block[\"text\"] += \" \"\n",
    "        current_block[\"text\"] += word\n",
    "        current_block[\"end\"] = end_time\n",
    "\n",
    "        if new_block_length > char_limit or ends_in_punctuation:\n",
    "            # Finalize and save the current block\n",
    "            blocks.append(current_block.copy())\n",
    "\n",
    "            # Start a new block\n",
    "            current_block = {\"text\": \"\", \"start\": None, \"end\": None}\n",
    "\n",
    "    # Add the last block if it's not empty\n",
    "    if current_block[\"text\"]:\n",
    "        blocks.append(current_block)\n",
    "\n",
    "    # Display the blocks\n",
    "    for block in blocks:\n",
    "        print(block)\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "\n",
    "subtitle_blocks= generate_subtitle_blocks(fixed_missing_time_stamps, char_limit=10)\n",
    "# print(subtitle_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_blocks(block_list):\n",
    "    # Initialize an empty list to hold the processed blocks\n",
    "    processed_blocks = []\n",
    "    \n",
    "    # Add an empty block that starts at 0 and ends at the start of the original first block\n",
    "    if block_list:\n",
    "        processed_blocks.append({'text': '', 'start': 0, 'end': block_list[0]['start']})\n",
    "    \n",
    "    # Loop through the list to process each block\n",
    "    for i, block in enumerate(block_list):\n",
    "        # Remove the block if it's the first one and the text is empty\n",
    "        if i == 0 and not block['text'].strip():\n",
    "            continue\n",
    "        \n",
    "        # Make the end time of a block the start time of the next block\n",
    "        if i < len(block_list) - 1:\n",
    "            block['end'] = block_list[i + 1]['start']\n",
    "        \n",
    "        processed_blocks.append(block)\n",
    "    \n",
    "    return processed_blocks\n",
    "\n",
    "\n",
    "processed_blocks = process_blocks(subtitle_blocks)\n",
    "print(processed_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_srt_time(seconds):\n",
    "    \"\"\"Convert seconds to SRT time format (HH:MM:SS,MMM)\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds % 1) * 1000)\n",
    "    seconds = int(seconds)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
    "\n",
    "def blocks_to_srt(processed_blocks):\n",
    "    \"\"\"Convert list of processed blocks to SRT format\"\"\"\n",
    "    srt_content = \"\"\n",
    "    for i, block in enumerate(processed_blocks, 1):\n",
    "        start_time = seconds_to_srt_time(block['start'])\n",
    "        end_time = seconds_to_srt_time(block['end'])\n",
    "        text = block['text']\n",
    "        \n",
    "        srt_content += f\"{i}\\n\"\n",
    "        srt_content += f\"{start_time} --> {end_time}\\n\"\n",
    "        srt_content += f\"{text}\\n\\n\"\n",
    "    \n",
    "    return srt_content\n",
    "\n",
    "\n",
    "srt_content = blocks_to_srt(processed_blocks)\n",
    "print(srt_content)\n",
    "\n",
    "# To write the content to an SRT file\n",
    "with open(\"output.srt\", \"w\") as f:\n",
    "    f.write(srt_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'Once', 'start': 0.268, 'end': 0.408, 'score': 0.804}\n",
      "{'word': 'upon', 'start': 0.468, 'end': 0.688, 'score': 0.766}\n",
      "{'word': 'a', 'start': 0.729, 'end': 0.749, 'score': 1.0}\n",
      "{'word': 'time,', 'start': 0.809, 'end': 1.029, 'score': 0.76}\n",
      "{'word': 'Emily', 'start': 1.409, 'end': 1.649, 'score': 0.813}\n",
      "{'word': 'faced', 'start': 1.709, 'end': 1.989, 'score': 0.785}\n",
      "{'word': 'the', 'start': 2.009, 'end': 2.109, 'score': 0.834}\n",
      "{'word': 'colossal', 'start': 2.15, 'end': 2.89, 'score': 0.754}\n",
      "{'word': 'mountain', 'start': 2.95, 'end': 3.29, 'score': 0.794}\n",
      "{'word': 'of', 'start': 3.35, 'end': 3.41, 'score': 0.752}\n",
      "{'word': 'student', 'start': 3.531, 'end': 3.951, 'score': 0.862}\n",
      "{'word': 'debt,', 'start': 3.991, 'end': 4.251, 'score': 0.952}\n",
      "{'word': 'feeling', 'start': 4.731, 'end': 5.052, 'score': 0.783}\n",
      "{'word': 'overwhelmed', 'start': 5.272, 'end': 5.912, 'score': 0.759}\n",
      "{'word': 'and', 'start': 5.952, 'end': 6.032, 'score': 0.835}\n",
      "{'word': 'suffocated', 'start': 6.132, 'end': 6.693, 'score': 0.925}\n",
      "{'word': 'by', 'start': 6.753, 'end': 6.873, 'score': 0.815}\n",
      "{'word': 'the', 'start': 6.893, 'end': 6.993, 'score': 0.777}\n",
      "{'word': 'numbers.', 'start': 7.033, 'end': 7.353, 'score': 0.919}\n",
      "{'word': 'Each', 'start': 7.934, 'end': 8.134, 'score': 0.712}\n",
      "{'word': 'bill', 'start': 8.234, 'end': 8.534, 'score': 0.918}\n",
      "{'word': 'in', 'start': 8.594, 'end': 8.674, 'score': 0.832}\n",
      "{'word': 'the', 'start': 8.714, 'end': 8.794, 'score': 0.833}\n",
      "{'word': 'mailbox', 'start': 8.834, 'end': 9.335, 'score': 0.907}\n",
      "{'word': 'served', 'start': 9.395, 'end': 9.755, 'score': 0.854}\n",
      "{'word': 'as', 'start': 9.915, 'end': 9.995, 'score': 0.69}\n",
      "{'word': 'a', 'start': 10.055, 'end': 10.095, 'score': 0.5}\n",
      "{'word': 'constant', 'start': 10.215, 'end': 10.696, 'score': 0.834}\n",
      "{'word': 'reminder', 'start': 10.736, 'end': 11.256, 'score': 0.879}\n",
      "{'word': 'of', 'start': 11.736, 'end': 11.816, 'score': 0.708}\n",
      "{'word': 'her', 'start': 11.876, 'end': 12.037, 'score': 0.694}\n",
      "{'word': 'inability', 'start': 12.197, 'end': 12.777, 'score': 0.871}\n",
      "{'word': 'to', 'start': 12.817, 'end': 12.897, 'score': 0.754}\n",
      "{'word': 'pursue', 'start': 12.937, 'end': 13.237, 'score': 0.824}\n",
      "{'word': 'her', 'start': 13.277, 'end': 13.377, 'score': 0.872}\n",
      "{'word': 'true', 'start': 13.438, 'end': 13.618, 'score': 0.994}\n",
      "{'word': 'passion.', 'start': 13.678, 'end': 14.118, 'score': 0.945}\n",
      "{'word': 'Wildlife', 'start': 14.758, 'end': 15.439, 'score': 0.922}\n",
      "{'word': 'photography,', 'start': 15.479, 'end': 16.159, 'score': 0.866}\n",
      "{'word': 'Then', 'start': 17.02, 'end': 17.16, 'score': 0.915}\n",
      "{'word': 'one', 'start': 17.26, 'end': 17.361, 'score': 0.832}\n",
      "{'word': 'day,', 'start': 17.401, 'end': 17.581, 'score': 0.638}\n",
      "{'word': 'inspired', 'start': 17.681, 'end': 18.061, 'score': 0.936}\n",
      "{'word': 'by', 'start': 18.081, 'end': 18.201, 'score': 0.708}\n",
      "{'word': 'a', 'start': 18.221, 'end': 18.242, 'score': 0.231}\n",
      "{'word': 'lecture', 'start': 18.302, 'end': 18.582, 'score': 0.904}\n",
      "{'word': 'from', 'start': 18.602, 'end': 18.742, 'score': 0.79}\n",
      "{'word': 'a', 'start': 18.802, 'end': 18.842, 'score': 0.449}\n",
      "{'word': 'famous', 'start': 18.922, 'end': 19.283, 'score': 0.894}\n",
      "{'word': 'photographer,', 'start': 19.323, 'end': 19.943, 'score': 0.897}\n",
      "{'word': 'she', 'start': 19.983, 'end': 20.104, 'score': 0.829}\n",
      "{'word': 'took', 'start': 20.164, 'end': 20.364, 'score': 0.848}\n",
      "{'word': 'out', 'start': 20.444, 'end': 20.524, 'score': 1.0}\n",
      "{'word': 'her', 'start': 20.564, 'end': 20.664, 'score': 0.721}\n",
      "{'word': 'old', 'start': 20.704, 'end': 20.824, 'score': 0.833}\n",
      "{'word': 'camera', 'start': 20.864, 'end': 21.325, 'score': 0.87}\n",
      "{'word': 'and', 'start': 21.405, 'end': 21.485, 'score': 0.836}\n",
      "{'word': 'began', 'start': 21.545, 'end': 21.926, 'score': 0.892}\n",
      "{'word': 'capturing', 'start': 22.066, 'end': 22.747, 'score': 0.89}\n",
      "{'word': 'the', 'start': 23.107, 'end': 23.207, 'score': 0.864}\n",
      "{'word': 'beauty', 'start': 23.307, 'end': 23.688, 'score': 0.861}\n",
      "{'word': 'of', 'start': 23.728, 'end': 23.808, 'score': 0.652}\n",
      "{'word': 'the', 'start': 23.848, 'end': 23.928, 'score': 0.831}\n",
      "{'word': 'local', 'start': 23.968, 'end': 24.288, 'score': 0.885}\n",
      "{'word': 'forest.', 'start': 24.368, 'end': 24.789, 'score': 0.838}\n",
      "{'word': 'She', 'start': 25.169, 'end': 25.269, 'score': 0.839}\n",
      "{'word': 'used', 'start': 25.39, 'end': 25.53, 'score': 0.874}\n",
      "{'word': 'her', 'start': 25.57, 'end': 25.69, 'score': 0.669}\n",
      "{'word': 'small', 'start': 25.81, 'end': 26.21, 'score': 0.91}\n",
      "{'word': 'social', 'start': 26.311, 'end': 26.671, 'score': 0.583}\n",
      "{'word': 'media', 'start': 26.711, 'end': 26.991, 'score': 0.99}\n",
      "{'word': 'following', 'start': 27.031, 'end': 27.432, 'score': 0.845}\n",
      "{'word': 'to', 'start': 27.872, 'end': 27.972, 'score': 0.998}\n",
      "{'word': 'display', 'start': 28.012, 'end': 28.393, 'score': 0.739}\n",
      "{'word': 'her', 'start': 28.433, 'end': 28.533, 'score': 0.686}\n",
      "{'word': 'work,', 'start': 28.573, 'end': 28.813, 'score': 0.817}\n",
      "{'word': 'and', 'start': 28.893, 'end': 28.974, 'score': 0.947}\n",
      "{'word': 'soon', 'start': 29.054, 'end': 29.294, 'score': 0.876}\n",
      "{'word': 'enough', 'start': 29.334, 'end': 29.594, 'score': 0.861}\n",
      "{'word': 'she', 'start': 29.654, 'end': 29.774, 'score': 0.661}\n",
      "{'word': 'attracted', 'start': 29.835, 'end': 30.315, 'score': 0.845}\n",
      "{'word': 'the', 'start': 30.355, 'end': 30.455, 'score': 0.706}\n",
      "{'word': 'attention', 'start': 30.495, 'end': 30.916, 'score': 0.804}\n",
      "{'word': 'of', 'start': 30.956, 'end': 31.016, 'score': 0.853}\n",
      "{'word': 'a', 'start': 31.076, 'end': 31.096, 'score': 0.994}\n",
      "{'word': 'local', 'start': 31.156, 'end': 31.456, 'score': 0.828}\n",
      "{'word': 'art', 'start': 31.556, 'end': 31.697, 'score': 0.843}\n",
      "{'word': 'gallery.', 'start': 31.737, 'end': 32.217, 'score': 0.854}\n",
      "{'word': 'The', 'start': 32.638, 'end': 32.738, 'score': 0.827}\n",
      "{'word': 'gallery', 'start': 32.778, 'end': 33.258, 'score': 0.921}\n",
      "{'word': 'offered', 'start': 33.619, 'end': 33.859, 'score': 0.857}\n",
      "{'word': 'to', 'start': 33.899, 'end': 33.979, 'score': 0.846}\n",
      "{'word': 'host', 'start': 34.019, 'end': 34.3, 'score': 0.757}\n",
      "{'word': 'an', 'start': 34.36, 'end': 34.42, 'score': 0.753}\n",
      "{'word': 'exhibition', 'start': 34.48, 'end': 34.98, 'score': 0.901}\n",
      "{'word': 'of', 'start': 35.02, 'end': 35.08, 'score': 0.752}\n",
      "{'word': 'her', 'start': 35.12, 'end': 35.241, 'score': 0.684}\n",
      "{'word': 'photography,', 'start': 35.281, 'end': 35.901, 'score': 0.927}\n",
      "{'word': 'and', 'start': 36.282, 'end': 36.382, 'score': 0.779}\n",
      "{'word': 'it', 'start': 36.462, 'end': 36.522, 'score': 0.948}\n",
      "{'word': 'was', 'start': 36.582, 'end': 36.722, 'score': 0.783}\n",
      "{'word': 'a', 'start': 36.782, 'end': 36.822, 'score': 0.499}\n",
      "{'word': 'resounding', 'start': 36.882, 'end': 37.423, 'score': 0.885}\n",
      "{'word': 'success.', 'start': 37.483, 'end': 37.824, 'score': 0.872}\n",
      "{'word': 'Using', 'start': 39.133, 'end': 39.393, 'score': 0.771}\n",
      "{'word': 'the', 'start': 39.614, 'end': 39.714, 'score': 0.85}\n",
      "{'word': 'funds', 'start': 39.794, 'end': 40.134, 'score': 0.833}\n",
      "{'word': 'from', 'start': 40.214, 'end': 40.394, 'score': 0.845}\n",
      "{'word': 'the', 'start': 40.454, 'end': 40.534, 'score': 0.916}\n",
      "{'word': 'sold', 'start': 40.614, 'end': 40.915, 'score': 0.932}\n",
      "{'word': 'pieces,', 'start': 40.955, 'end': 41.335, 'score': 0.84}\n",
      "{'word': 'Emily', 'start': 41.655, 'end': 41.976, 'score': 0.887}\n",
      "{'word': 'managed', 'start': 42.036, 'end': 42.416, 'score': 0.833}\n",
      "{'word': 'to', 'start': 42.456, 'end': 42.536, 'score': 0.752}\n",
      "{'word': 'pay', 'start': 42.576, 'end': 42.756, 'score': 0.875}\n",
      "{'word': 'off', 'start': 42.816, 'end': 42.956, 'score': 0.823}\n",
      "{'word': 'a', 'start': 43.016, 'end': 43.036, 'score': 0.999}\n",
      "{'word': 'significant', 'start': 43.096, 'end': 43.657, 'score': 0.927}\n",
      "{'word': 'chunk', 'start': 43.697, 'end': 43.937, 'score': 0.861}\n",
      "{'word': 'of', 'start': 43.997, 'end': 44.057, 'score': 0.782}\n",
      "{'word': 'her', 'start': 44.097, 'end': 44.237, 'score': 0.75}\n",
      "{'word': 'debt,', 'start': 44.317, 'end': 44.638, 'score': 0.89}\n",
      "{'word': 'liberating', 'start': 45.018, 'end': 45.559, 'score': 0.809}\n",
      "{'word': 'her', 'start': 45.619, 'end': 45.739, 'score': 0.807}\n",
      "{'word': 'to', 'start': 45.779, 'end': 45.859, 'score': 0.869}\n",
      "{'word': 'take', 'start': 45.919, 'end': 46.119, 'score': 0.841}\n",
      "{'word': 'more', 'start': 46.179, 'end': 46.379, 'score': 0.828}\n",
      "{'word': 'daring', 'start': 46.439, 'end': 46.78, 'score': 0.871}\n",
      "{'word': 'trips', 'start': 46.82, 'end': 47.06, 'score': 0.847}\n",
      "{'word': 'for', 'start': 47.1, 'end': 47.22, 'score': 0.795}\n",
      "{'word': 'even', 'start': 47.28, 'end': 47.48, 'score': 0.814}\n",
      "{'word': 'better', 'start': 47.54, 'end': 47.82, 'score': 0.894}\n",
      "{'word': 'shots.', 'start': 47.88, 'end': 48.221, 'score': 0.994}\n",
      "{'word': 'More', 'start': 49.586, 'end': 49.826, 'score': 0.626}\n",
      "{'word': 'exhibitions', 'start': 49.966, 'end': 50.526, 'score': 0.858}\n",
      "{'word': 'followed,', 'start': 50.606, 'end': 50.926, 'score': 0.89}\n",
      "{'word': 'each', 'start': 51.187, 'end': 51.347, 'score': 0.844}\n",
      "{'word': 'more', 'start': 51.407, 'end': 51.547, 'score': 0.863}\n",
      "{'word': 'successful', 'start': 51.607, 'end': 52.087, 'score': 0.91}\n",
      "{'word': 'than', 'start': 52.127, 'end': 52.247, 'score': 0.875}\n",
      "{'word': 'the', 'start': 52.267, 'end': 52.367, 'score': 0.674}\n",
      "{'word': 'last,', 'start': 52.407, 'end': 52.747, 'score': 0.907}\n",
      "{'word': 'until', 'start': 53.507, 'end': 53.847, 'score': 0.88}\n",
      "{'word': 'she', 'start': 53.887, 'end': 53.988, 'score': 0.667}\n",
      "{'word': 'was', 'start': 54.028, 'end': 54.148, 'score': 0.658}\n",
      "{'word': 'finally', 'start': 54.208, 'end': 54.588, 'score': 0.84}\n",
      "{'word': 'free', 'start': 54.688, 'end': 54.888, 'score': 0.805}\n",
      "{'word': 'of', 'start': 54.928, 'end': 54.968, 'score': 1.0}\n",
      "{'word': 'debt.', 'start': 55.028, 'end': 55.288, 'score': 0.986}\n",
      "{'word': 'With', 'start': 55.768, 'end': 55.908, 'score': 0.906}\n",
      "{'word': 'her', 'start': 55.948, 'end': 56.048, 'score': 0.927}\n",
      "{'word': 'newfound', 'start': 56.088, 'end': 56.568, 'score': 0.892}\n",
      "{'word': 'financial', 'start': 56.628, 'end': 57.169, 'score': 0.865}\n",
      "{'word': 'freedom,', 'start': 57.229, 'end': 57.549, 'score': 0.942}\n",
      "{'word': 'Emily', 'start': 58.229, 'end': 58.509, 'score': 0.847}\n",
      "{'word': 'established', 'start': 58.549, 'end': 59.129, 'score': 0.79}\n",
      "{'word': 'a', 'start': 59.289, 'end': 59.329, 'score': 0.997}\n",
      "{'word': 'wildlife', 'start': 59.409, 'end': 59.99, 'score': 0.865}\n",
      "{'word': 'sanctuary,', 'start': 60.03, 'end': 60.71, 'score': 0.779}\n",
      "{'word': 'combining', 'start': 61.19, 'end': 61.67, 'score': 0.862}\n",
      "{'word': 'her', 'start': 61.71, 'end': 61.81, 'score': 0.743}\n",
      "{'word': 'passion', 'start': 61.85, 'end': 62.21, 'score': 0.877}\n",
      "{'word': 'for', 'start': 62.23, 'end': 62.35, 'score': 0.675}\n",
      "{'word': 'photography', 'start': 62.39, 'end': 62.951, 'score': 0.998}\n",
      "{'word': 'and', 'start': 62.991, 'end': 63.071, 'score': 0.836}\n",
      "{'word': 'conservation.', 'start': 63.111, 'end': 63.871, 'score': 0.899}\n",
      "{'word': 'Her', 'start': 64.711, 'end': 64.831, 'score': 0.672}\n",
      "{'word': 'story', 'start': 64.891, 'end': 65.211, 'score': 0.861}\n",
      "{'word': 'spread,', 'start': 65.271, 'end': 65.711, 'score': 0.743}\n",
      "{'word': 'and', 'start': 66.132, 'end': 66.232, 'score': 0.869}\n",
      "{'word': 'soon', 'start': 66.332, 'end': 66.572, 'score': 0.842}\n",
      "{'word': 'she', 'start': 66.652, 'end': 66.752, 'score': 0.692}\n",
      "{'word': 'was', 'start': 66.772, 'end': 66.892, 'score': 0.635}\n",
      "{'word': 'invited', 'start': 66.932, 'end': 67.312, 'score': 0.907}\n",
      "{'word': 'to', 'start': 67.432, 'end': 67.532, 'score': 0.946}\n",
      "{'word': 'give', 'start': 67.612, 'end': 67.792, 'score': 0.756}\n",
      "{'word': 'lectures,', 'start': 67.832, 'end': 68.312, 'score': 0.798}\n",
      "{'word': 'inspiring', 'start': 68.893, 'end': 69.473, 'score': 0.851}\n",
      "{'word': 'the', 'start': 69.513, 'end': 69.593, 'score': 0.832}\n",
      "{'word': 'next', 'start': 69.633, 'end': 69.853, 'score': 0.85}\n",
      "{'word': 'generation', 'start': 69.893, 'end': 70.513, 'score': 0.893}\n",
      "{'word': 'to', 'start': 70.773, 'end': 70.913, 'score': 0.774}\n",
      "{'word': 'conquer', 'start': 70.973, 'end': 71.253, 'score': 0.974}\n",
      "{'word': 'their', 'start': 71.293, 'end': 71.433, 'score': 0.851}\n",
      "{'word': 'obstacles', 'start': 71.533, 'end': 71.954, 'score': 0.694}\n",
      "{'word': 'just', 'start': 72.054, 'end': 72.314, 'score': 0.818}\n",
      "{'word': 'as', 'start': 72.394, 'end': 72.454, 'score': 1.0}\n",
      "{'word': 'she', 'start': 72.494, 'end': 72.634, 'score': 0.54}\n",
      "{'word': 'had.', 'start': 72.674, 'end': 72.874, 'score': 0.998}\n",
      "{'word': 'Emily', 'start': 74.743, 'end': 74.984, 'score': 0.947}\n",
      "{'word': 'looked', 'start': 75.024, 'end': 75.224, 'score': 0.917}\n",
      "{'word': 'at', 'start': 75.264, 'end': 75.305, 'score': 0.998}\n",
      "{'word': 'her', 'start': 75.345, 'end': 75.445, 'score': 0.839}\n",
      "{'word': 'life,', 'start': 75.505, 'end': 75.786, 'score': 0.932}\n",
      "{'word': 'realizing', 'start': 76.367, 'end': 76.928, 'score': 0.829}\n",
      "{'word': 'that', 'start': 76.969, 'end': 77.089, 'score': 0.877}\n",
      "{'word': 'she', 'start': 77.129, 'end': 77.249, 'score': 0.667}\n",
      "{'word': 'had', 'start': 77.269, 'end': 77.35, 'score': 0.903}\n",
      "{'word': 'transformed', 'start': 77.49, 'end': 78.412, 'score': 0.855}\n",
      "{'word': 'her', 'start': 78.432, 'end': 78.633, 'score': 0.56}\n",
      "{'word': 'mountain', 'start': 78.753, 'end': 79.194, 'score': 0.841}\n",
      "{'word': 'of', 'start': 79.234, 'end': 79.274, 'score': 1.0}\n",
      "{'word': 'debt', 'start': 79.354, 'end': 79.615, 'score': 0.963}\n",
      "{'word': 'into', 'start': 80.096, 'end': 80.337, 'score': 0.876}\n",
      "{'word': 'a', 'start': 80.377, 'end': 80.417, 'score': 0.499}\n",
      "{'word': 'mountain', 'start': 80.537, 'end': 80.918, 'score': 0.757}\n",
      "{'word': 'of', 'start': 80.938, 'end': 80.998, 'score': 0.75}\n",
      "{'word': 'dreams,', 'start': 81.079, 'end': 81.56, 'score': 0.715}\n",
      "{'word': 'climbed', 'start': 82.081, 'end': 82.682, 'score': 0.752}\n",
      "{'word': 'and', 'start': 82.763, 'end': 82.863, 'score': 0.799}\n",
      "{'word': 'conquered.', 'start': 83.003, 'end': 83.444, 'score': 0.861}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# filepath = \"word_segments.json\"\n",
    "with open(\"word_segments.json\", \"r\") as json_file:\n",
    "    word_segments = json.load(json_file)\n",
    "\n",
    "\n",
    "\n",
    "# for item in word_segments:\n",
    "#     print(item)\n",
    "\n",
    "\n",
    "\n",
    "import transcriber\n",
    "word_list = transcriber.process_word_segments(word_segments)\n",
    "for word in word_list:\n",
    "    print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
